# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Chatbot wrapper API with adapter-based architecture supporting multiple AI model providers. Currently supports OpenAI API, local vLLM models, and OpenAI-compatible providers.

**Note**: Backend API service. Frontend: `../chatbot-frontend`. Deployment: AWS Lambda + API Gateway + Cognito serverless architecture.

## Current Status

**Phase 1 - Project Foundation: ‚úÖ COMPLETED**
- ‚úÖ Directory structure created with all planned modules
- ‚úÖ Python package structure with `__init__.py` files
- ‚úÖ Requirements.txt with FastAPI, vLLM, and essential dependencies
- ‚úÖ pyproject.toml with project metadata and development tools
- ‚úÖ Environment configuration (.env.example, .gitignore)
- ‚úÖ Updated README.md with setup instructions (including uv support)

**Phase 2 - Core Model Adapters: ‚úÖ COMPLETED**
- ‚úÖ OpenAI adapter implementation supporting OpenAI API, local vLLM models, and OpenAI-compatible providers
- ‚úÖ Model registry system for dynamic model configuration
- ‚úÖ Settings management with environment variable support
- ‚úÖ Unified chat completion interface across different model backends

**Phase 3 - API Endpoints & Chat Interface: ‚úÖ COMPLETED**
- ‚úÖ FastAPI application structure with main app file
- ‚úÖ Chat completion endpoints using existing OpenAI adapter
- ‚úÖ Health check and status endpoints (live, ready, comprehensive)
- ‚úÖ Request/response models with Pydantic validation
- ‚úÖ Error handling and logging middleware
- ‚úÖ Adapter factory integrating with model configuration
- ‚úÖ OpenAI-compatible API endpoints
- ‚úÖ Streaming and non-streaming chat completions
- ‚úÖ Model listing endpoint
- ‚úÖ Installation and testing infrastructure

**Phase 4 - Authentication System: ‚úÖ COMPLETED**
- ‚úÖ Auth0 configuration settings added to settings.py
- ‚úÖ Authentication models created (src/auth/models.py)
- ‚úÖ Auth module structure established (src/auth/)
- ‚úÖ Auth0 client implementation with institution registry
- ‚úÖ JWT middleware for token validation
- ‚úÖ Authentication API endpoints with onboarding flow
- ‚úÖ User management system with role storage
- ‚úÖ Integration with main FastAPI application


## Development Commands

### Key Commands for Claude
- `python run_server.py` - Start the chatbot service
- `python test_api.py` - Test API endpoints
- `uv pip install -r requirements-api-only.txt` - Install dependencies
- `black . && isort . && flake8 . && mypy src/` - Code quality checks

## Implementation Guidelines

### Code Conventions
- Follow existing adapter pattern when adding new providers
- Use Pydantic models for configuration and validation
- Implement structured logging with JSON format
- Never commit API keys or sensitive configuration
- Use environment variables for secrets management

## Authentication Implementation

**Current Status**: Auth0-based SSO with institution registry for educational pilot

**Key Components**:
- **Auth Models** (`src/auth/models.py`): User, session, and institution data structures
- **Auth0 Client** (`src/auth/auth0_client.py`): OAuth flows + institution registry lookup
- **JWT Middleware** (`src/auth/middleware.py`): Token validation and user context
- **Auth Endpoints** (`src/auth/auth.py`): Login, callback, onboarding, profile management
- **User Manager** (`src/auth/user_manager.py`): In-memory user and session management

**Supported Methods**: Google, Microsoft, SAML, GitHub, Individual accounts

## Next Steps (Phase 5+ Implementation)

1. **AWS Lambda Deployment** (Phase 5 - Next Priority):
   - **Lambda Handler**: Implement Mangum wrapper for FastAPI on AWS Lambda
   - **CDK Infrastructure**: AWS CDK stack for Lambda, API Gateway, Cognito, S3, CloudFront
   - **Cognito Integration**: Replace Auth0 with AWS Cognito User Pools for authentication
   - **API Gateway**: HTTP API with Cognito authorizer for cost optimization
   - **Environment Configuration**: Lambda environment variables and secrets management
   - **CI/CD Pipeline**: Automated testing, building, and serverless deployment workflows

2. **Database Integration** (Phase 6):
   - **DynamoDB Implementation**: Replace in-memory user storage with AWS DynamoDB
   - **Database Schema**: User profiles, sessions, chat history, and analytics tables
   - **Migration System**: DynamoDB table creation and schema management
   - **Analytics Queries**: DynamoDB queries for user behavior analysis and reporting
   - **Data Export**: S3 data lake integration for analytics and reporting
   - **Serverless Persistence**: Native AWS serverless database integration

3. **Additional Model Providers** (Phase 7):
   - **Anthropic Adapter** (`src/models/adapters/anthropic_adapter.py`): Claude model integration
   - **Google Adapter** (`src/models/adapters/google_adapter.py`): Gemini model support
   - **Enhanced Model Registry**: Provider-specific configurations and capability detection

4. **Enhanced Data Collection System** (Phase 8):
   - **Conversation Analytics**: Track usage patterns, model performance, user engagement
   - **Real-time Metrics**: API response times, error rates, user activity dashboards
   - **Data Analysis Tools**: Built-in analytics endpoints for team insights
   - **Privacy Controls**: FERPA compliance, data retention policies, user data deletion

## Current Implementation Status

### Completed Components
- ‚úÖ **OpenAI Adapter** (`src/models/openai_adapter.py`): Supports OpenAI API, vLLM, and compatible providers
- ‚úÖ **Model Configuration** (`src/config/models.py`): Centralized model registry with Pydantic validation
- ‚úÖ **Adapter Factory** (`src/models/adapter_factory.py`): Runtime adapter management and health checks
- ‚úÖ **Settings Management** (`src/config/settings.py`): Environment-based configuration with Auth0 support
- ‚úÖ **FastAPI Application** (`src/api/main.py`): Complete web server with middleware and error handling
- ‚úÖ **API Routes** (`src/api/routes/`): Chat completions, health checks, model listing, and authentication
- ‚úÖ **API Models** (`src/api/models.py`): OpenAI-compatible request/response models
- ‚úÖ **Base Interfaces** (`src/models/base.py`): Abstract adapter interface and common models
- ‚úÖ **Authentication System** (`src/auth/`): Complete Auth0 integration with JWT middleware
  - ‚úÖ **Auth0 Client** (`src/auth/auth0_client.py`): OAuth flows and institution registry
  - ‚úÖ **JWT Middleware** (`src/auth/middleware.py`): Token validation and user context
  - ‚úÖ **Auth Endpoints** (`src/auth/auth.py`): Login, callback, onboarding, profile management
  - ‚úÖ **User Manager** (`src/auth/user_manager.py`): In-memory user and session management
- ‚úÖ **Testing Infrastructure** (`test_api.py`, `run_server.py`): Development and testing tools
- ‚úÖ **Installation Setup** (`requirements-api-only.txt`): Lightweight dependency management


## Current Working State

The application is now **fully functional** for Phase 3 objectives:

### ‚úÖ Ready to Use
- **Installation**: `uv pip install -r requirements-api-only.txt`
- **Startup**: `python run_server.py`
- **Testing**: `python test_api.py`
- **API Docs**: `http://localhost:8000/docs`

### ‚úÖ Working Features
- OpenAI-compatible REST API endpoints
- Health checks and status monitoring
- Model listing and discovery
- Chat completions (streaming and non-streaming)
- Error handling with structured logging
- Kubernetes-ready health probes

### ‚ö†Ô∏è Configuration Required
To use actual models, users need to:
1. **For OpenAI**: Set `OPENAI_API_KEY` environment variable
2. **For local vLLM**: Start vLLM server on `localhost:8001` with OpenAI-compatible API
3. **For other providers**: Configure API endpoints in model registry

### üîß Development Tools
- `run_server.py`: Simple server startup with graceful shutdown
- `test_api.py`: Comprehensive API endpoint testing
- `requirements-api-only.txt`: Fast installation without heavy ML dependencies
- Interactive API documentation at `/docs` endpoint